---
title: Insert title here
key: 428af9dcb37795f7be345b5281397cda
video_link:
  mp3: https://assets.datacamp.com/production/repositories/3490/datasets/bedacecdaab52f8bfc9c732e8fb690b11c56ed5e/audio_recording_3.mp3

---
## Introduction to PySpark RDD

```yaml
type: "TitleSlide"
key: "2fe2adb764"
```

`@lower_third`

name: Upendra Devisetty
title: Science Analyst, CyVerse


`@script`



---
## RDDs in PySpark

```yaml
type: "FullSlide"
key: "fe4f59f0a1"
```

`@part1`
- What is RDD?

- Creating RDDs
  * Parallelize method
  * Existing RDDs
  * External datasets

- Basic RDD operations
  * Transformations (Map, Filter, FlatMap)
  * Actions (Collect, Take, First, Count)


`@script`



---
## What is RDD?

```yaml
type: "FullSlide"
key: "c808f99a10"
```

`@part1`
- Data in Spark is organized into RDD, DataFrames and Datasets

- Fundamental and backbone of Spark

- Immutable distributed collection of records, partitioned across nodes in the cluster

- **R**esilient **D**istributed **D**atasets

- **Resilient** - Ability to withstand failures 

- **Distributed** - Spanning across multiple machines


`@script`



---
## Creating RDDs

```yaml
type: "FullSlide"
key: "9b655426f4"
center_content: true
```

`@part1`
- Parallelizing an existing collection
```
num = sc.parallelize([1,2,3,4])
```

- From existing RDDs
```
num_map = num.map(lambda x: x * x)
```

- External datasets: Files in HDFS, objects in Amazon S3, lines in a text file..
```
file = sc.textFile("movie.data")
```


`@script`



---
## Basic RDD Transformations

```yaml
type: "FullSlide"
key: "89aeffa5da"
```

`@part1`
- Operations applied on a RDD to create new RDD

- Transformations follow the principle of Lazy Evaluations

- **Map**

- **Filter**

- **FlatMap**


`@script`



---
## Map Transformation

```yaml
type: "FullSlide"
key: "d89b715c91"
```

`@part1`
- **Map** is the transformation that takes a function and applies it to each element of RDD. 

- The result of the function, will become the value of each element in the resulting RDD

![](https://assets.datacamp.com/production/repositories/3490/datasets/342050bd8b7964af47d678cdeb0f5496d0730fa0/map_transformation.png)


`@script`



---
## Filter Transformation

```yaml
type: "FullSlide"
key: "91fb0ad7c3"
```

`@part1`
- **Filter** is the transformation that returns a new RDD with only the elements that passes the filter condition

![](https://assets.datacamp.com/production/repositories/3490/datasets/2204183ae119fdc0ee8fec1088337fcb9b6dd5bd/filter_transformation.png)


`@script`



---
## FlatMap Transformation

```yaml
type: "FullSlide"
key: "42ba21eee1"
```

`@part1`
- Similar to map except **flatMap** returns multiple values for each element in the source RDD 

![](https://assets.datacamp.com/production/repositories/3490/datasets/e51b7f40b547ff4a9fc0fd512cb94fa7e404c35d/flatmap_transformation.png)


`@script`



---
## Basic RDD Actions

```yaml
type: "FullSlide"
key: "2dee493260"
```

`@part1`
- Operation return a value to the driver program after running a computation on the dataset

- **Collect**

- **Take**

- **First**

- **Count**


`@script`



---
## Collect and Take Actions

```yaml
type: "FullSlide"
key: "0577bc157a"
```

`@part1`
- **Collect** return all the elements of the dataset as an array at the driver program

```
num = sc.parallelize([1,2,3,4])
```
```
squaredNumbersRDD = num.map(lambda x: x * x)
```
```
squaredNumbersRDD.collect()
[1, 4, 9, 16]
```

- **Take** return an array with the first n elements of the dataset.

```
file = sc.textFile("movie.data")
```
```
file.take(4)
["1::Toy Story (1995)::Animation|Children's|Comedy", "2::Jumanji (1995)::Adventure|Children's|Fantasy", '3::Grumpier Old Men (1995)::Comedy|Romance', '4::Waiting to Exhale (1995)::Comedy|Drama']
```


`@script`



---
## First and Count Transformation

```yaml
type: "FullSlide"
key: "9e5c1ba75b"
```

`@part1`
- **First** return the first element of the dataset (similar to take(1)).
```
file = sc.textFile("movie.data")
file.first()
"1::Toy Story (1995)::Animation|Children's|Comedy"
```

- **Count** return the number of elements in the dataset.
```
file = sc.textFile("movie.data")
file.count()
3883
```


`@script`



---
## Let's Practice

```yaml
type: "FinalSlide"
key: "a59e80f8a0"
```

`@script`


